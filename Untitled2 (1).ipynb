{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owFaYEQ1QeSP"
      },
      "source": [
        "Q 1)Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PTbQzkUQjOB"
      },
      "source": [
        "ANS ) ) Multithreading and multiprocessing are both techniques used to achieve parallelism in software development, but they are suited for different types of tasks depending on factors like the nature of the workload, how resources are shared, and how the underlying system behaves.\n",
        "Scenarios Where Multithreading Is Preferable\n",
        "1.\tI/O-bound tasks:\n",
        "o\tNetwork or file I/O: Multithreading is highly beneficial when the program is frequently waiting for I/O operations like reading from a disk, writing to a file, or making network requests. Threads can remain idle while waiting for I/O to complete, allowing others to execute.\n",
        "o\tWeb servers: A web server handling multiple client requests (which involve waiting for I/O) is a good candidate for multithreading, as it allows better resource utilization and responsiveness.\n",
        "2.\tShared memory access:\n",
        "o\tThread communication: Since threads share the same memory space, multithreading is more efficient when multiple tasks need to read/write shared data. Communication between threads is simpler and faster compared to processes, where inter-process communication (IPC) is required.\n",
        "o\tLightweight context switching: Threads are lighter than processes in terms of memory usage, and switching between threads is faster because they share memory. In applications where tasks frequently need to share state or synchronize, multithreading can be more efficient.\n",
        "3.\tCPU-bound tasks on platforms with a Global Interpreter Lock (GIL):\n",
        "o\tPython’s GIL: In languages like Python, where the GIL prevents multiple threads from executing Python bytecode in parallel, multithreading is still useful for I/O-bound operations. However, for CPU-bound tasks in Python, multithreading does not offer true parallelism (due to GIL), and multiprocessing is usually better in such cases.\n",
        "4.\tTasks requiring frequent context switching:\n",
        "o\tResponsiveness: Multithreading allows applications that require frequent switching between tasks (like user interfaces) to be more responsive because thread context switching is generally faster than process switching.\n",
        "5.\tLower resource overhead:\n",
        "o\tMemory efficiency: Threads within the same process share the same memory space, leading to lower memory overhead compared to creating separate processes. This makes multithreading preferable when you need many lightweight tasks running simultaneously.\n",
        "Scenarios Where Multiprocessing Is Preferable\n",
        "1.\tCPU-bound tasks:\n",
        "o\tTrue parallelism: For CPU-intensive operations (e.g., computation-heavy tasks like machine learning training, data processing, image rendering), multiprocessing is preferred because it can fully utilize multiple CPU cores. Each process runs in its own memory space, avoiding the GIL in languages like Python, allowing true parallel execution.\n",
        "o\tMulticore systems: On systems with multiple CPU cores, multiprocessing can distribute tasks across cores, significantly speeding up execution.\n",
        "2.\tAvoiding Global Interpreter Lock (GIL):\n",
        "o\tPython’s GIL: As mentioned, the GIL in languages like Python prevents true multithreading for CPU-bound tasks. Multiprocessing bypasses the GIL by running separate processes that do not share the same memory, enabling true parallelism on multi-core CPUs.\n",
        "3.\tIsolating tasks:\n",
        "o\tMemory isolation: In scenarios where tasks must be isolated from each other (e.g., for security or fault tolerance), multiprocessing is better. Each process has its own memory space, so if one process crashes or behaves incorrectly, it does not affect the others.\n",
        "o\tSandboxing: Multiprocessing is useful for tasks that require sandboxing or preventing side effects on shared memory. Each process operates independently, making it safer in systems where individual tasks should not interfere with each other.\n",
        "4.\tTask-specific memory management:\n",
        "o\tMemory-intensive tasks: For tasks that require large amounts of memory or need to allocate/deallocate memory frequently, multiprocessing provides more flexibility. Since each process has its own memory space, managing memory becomes easier and more isolated.\n",
        "5.\tParallelism across distributed systems:\n",
        "o\tDistributed computing: In systems where tasks are distributed across multiple machines or nodes (e.g., clusters or cloud computing environments), multiprocessing is a natural fit. Processes can run independently on different nodes and communicate using inter-process communication (IPC) or message passing protocols like MPI.\n",
        "6.\tFault tolerance:\n",
        "o\tCrash isolation: If an application involves critical operations where crashes or memory corruption must be isolated, multiprocessing provides better resilience. If a thread crashes, it can bring down the whole application. In contrast, if a process crashes, only that process is affected.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY0XSMOAQMv2"
      },
      "source": [
        "Q 2)Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj-aMAIGQVZX"
      },
      "source": [
        "Ans)) A process pool is a programming construct that allows efficient management and execution of multiple processes by maintaining a pool (or collection) of worker processes that can be reused. It simplifies parallel execution by providing a high-level interface for distributing tasks among multiple processes, reducing the overhead associated with repeatedly creating and destroying processes.\n",
        "Key Features of a Process Pool\n",
        "1.\tPool of Worker Processes: A process pool consists of a fixed or dynamically allocated number of processes. These processes are created when the pool is initialized and remain active to handle tasks, which avoids the cost of repeatedly spawning and terminating processes.\n",
        "2.\tTask Assignment: The tasks that need to be executed are distributed among the worker processes in the pool. The pool manages the assignment of tasks to available processes, ensuring that each process runs independently of the others and works on a different task.\n",
        "3.\tConcurrency Control: The number of processes in the pool is limited to a fixed number, ensuring that the system resources (like CPU cores) are not overwhelmed. The pool manages concurrency by executing only a limited number of tasks at a time, balancing load and preventing resource exhaustion.\n",
        "4.\tTask Scheduling: A process pool uses a scheduling mechanism to assign tasks to idle processes. When a process finishes its task, it is returned to the pool and can be assigned a new task without the overhead of process creation.\n",
        "5.\tAsynchronous Execution: Many process pools support asynchronous task submission, meaning tasks can be submitted without waiting for each to complete. This allows the main program to continue execution while tasks are processed in parallel.\n",
        "6.\tResult Aggregation: Once a process completes its task, the result is returned to the main program, often through callback mechanisms or future/promise objects, which allow the program to retrieve results once they are ready.\n",
        "How Process Pools Improve Efficiency\n",
        "1.\tReduced Process Creation Overhead:\n",
        "o\tCreating processes is costly in terms of system resources and time. A process pool creates a fixed number of processes upfront, reducing the overhead of spawning new processes for every task. The same processes are reused to handle multiple tasks, improving overall efficiency.\n",
        "2.\tEfficient Resource Utilization:\n",
        "o\tThe pool limits the number of active processes to a fixed size, typically equal to or less than the number of CPU cores, ensuring that processes do not compete for resources. This leads to better use of CPU and memory resources while avoiding oversubscription, which can cause performance degradation due to excessive context switching or memory contention.\n",
        "3.\tTask Parallelism:\n",
        "o\tA process pool allows multiple tasks to be executed in parallel by distributing them across the processes in the pool. Each process can work independently, achieving parallelism for CPU-bound tasks and improving the overall throughput of the program.\n",
        "4.\tSimplified Task Management:\n",
        "o\tWithout a process pool, a developer would need to manually manage process creation, task assignment, and resource cleanup. A process pool abstracts these details, providing a clean interface for submitting tasks, retrieving results, and managing worker processes, which simplifies parallel programming.\n",
        "5.\tScalability:\n",
        "o\tProcess pools can scale efficiently based on the system's available resources. By limiting the number of active processes, the pool helps prevent excessive resource consumption, making it easier to scale applications across multi-core systems or distributed environments.\n",
        "Example Usage (Python multiprocessing.Pool)\n",
        "In Python, the multiprocessing module provides a Pool class, which allows for easy management of worker processes.\n",
        "python\n",
        "import multiprocessing\n",
        "\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a pool of 4 worker processes\n",
        "    with multiprocessing.Pool(processes=4) as pool:\n",
        "        # Map the function 'square' to a list of numbers\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "    \n",
        "    print(results)\n",
        "In this example:\n",
        "•\tA pool of 4 processes is created.\n",
        "•\tThe map function distributes the tasks (squaring each number in the list) across the 4 processes.\n",
        "•\tThe pool manages task assignment and result collection, and when all tasks are complete, the results are returned to the main program.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r89soq6hPl5_"
      },
      "source": [
        "Q 3) Explain what multiprocessing is and why it is used in Python programs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRmzgPa8PrE4"
      },
      "source": [
        "Ans) ) Multiprocessing is a programming technique that allows a program to execute multiple processes in parallel. Each process runs independently in its own memory space and can be executed concurrently on multiple CPU cores, allowing for true parallel execution. This contrasts with multithreading, where multiple threads run within the same process and share the same memory space, but do not achieve true parallelism due to limitations like the Global Interpreter Lock (GIL) in languages like Python.\n",
        "In Python, multiprocessing is used to perform parallel execution of CPU-bound tasks and to bypass the limitations of the GIL, enabling programs to better utilize multi-core processors.\n",
        "                       Why Multiprocessing is Used in Python\n",
        "1.\tOvercoming the Global Interpreter Lock (GIL):\n",
        "o\tPython has a GIL that limits the execution of multiple threads. The GIL prevents multiple threads from executing Python bytecode at the same time, meaning only one thread can execute in the Python interpreter at any given moment. This makes Python multithreading unsuitable for CPU-bound tasks (which involve heavy computation).\n",
        "o\tMultiprocessing avoids the GIL because each process in Python has its own memory space and runs its own interpreter instance. This allows multiple processes to execute in parallel across multiple CPU cores, enabling true parallelism even for CPU-bound tasks.\n",
        "2.\tUtilizing Multiple CPU Cores:\n",
        "o\tMost modern computers have multi-core CPUs, which can execute several tasks in parallel. Python’s multiprocessing module allows a program to take advantage of these cores by distributing tasks across multiple processes, each running independently on a separate core. This results in improved performance for tasks that are computationally intensive (e.g., data processing, machine learning model training).\n",
        "3.\tEfficient Parallelism for CPU-bound Tasks:\n",
        "o\tCPU-bound tasks are those that require extensive computation and involve minimal I/O operations. Examples include mathematical computations, simulations, data transformations, and scientific computing. In these cases, multiprocessing is highly efficient because it allows multiple CPU cores to work on the problem simultaneously, speeding up execution time.\n",
        "4.\tFault Isolation:\n",
        "o\tSince each process in a multiprocessing environment runs in its own memory space, any faults, crashes, or memory leaks in one process do not affect others. This isolation makes multiprocessing more robust and safer for certain applications, especially when tasks are complex or prone to failure.\n",
        "5.\tBetter Resource Allocation:\n",
        "o\tProcesses have their own memory space, meaning memory-intensive tasks are better managed using multiprocessing. In multithreading, memory is shared between threads, which can lead to memory contention and data inconsistency. In multiprocessing, memory allocation is isolated per process, leading to more predictable and controlled resource usage.\n",
        "6.\tParallel Execution of Independent Tasks:\n",
        "o\tIn some cases, tasks are completely independent and can be executed in parallel without sharing data. For example, rendering different frames in an animation, training multiple machine learning models with different hyperparameters, or processing large chunks of data in parallel. Multiprocessing allows these independent tasks to be executed concurrently, maximizing efficiency.\n",
        "Multiprocessing in Python (Using the multiprocessing Module)\n",
        "Python provides a multiprocessing module that makes it easy to spawn multiple processes and distribute tasks across them. It provides tools for creating and managing processes, as well as for communication between them using pipes, queues, and shared memory.\n",
        "Example of Multiprocessing in Python:\n",
        "python\n",
        "import multiprocessing\n",
        "\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = [1, 2, 3, 4, 5]\n",
        "    \n",
        "    # Create a pool of worker processes\n",
        "    with multiprocessing.Pool(processes=4) as pool:\n",
        "        results = pool.map(square, numbers)\n",
        "    \n",
        "    print(results)\n",
        "•\tIn this example, a pool of 4 worker processes is created.\n",
        "•\tThe map function distributes the task of squaring each number in the list across the worker processes.\n",
        "•\tEach process runs independently and returns its result to the main program when done.\n",
        "Use Cases for Multiprocessing in Python\n",
        "1.\tScientific Computing and Data Processing:\n",
        "o\tTasks like matrix operations, simulations, and data transformations can benefit from multiprocessing to reduce computation time.\n",
        "2.\tMachine Learning and Deep Learning:\n",
        "o\tTraining models on large datasets or evaluating models with different parameters can be parallelized using multiprocessing, which speeds up these processes significantly.\n",
        "3.\tParallel Data Scraping:\n",
        "o\tMultiprocessing can be used to perform web scraping where multiple processes handle different URLs concurrently, leading to faster data collection.\n",
        "4.\tImage and Video Processing:\n",
        "o\tOperations such as filtering, resizing, and transforming large sets of images or video frames can be distributed across multiple processes to improve performance.\n",
        "5.\tSimulations and Monte Carlo Methods:\n",
        "o\tIn simulations that involve random sampling (e.g., Monte Carlo simulations), multiprocessing allows for faster execution by distributing samples across processes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWCmPRkiDyCL"
      },
      "outputs": [],
      "source": [
        "Q 4 Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KScXDKdICsCW",
        "outputId": "2b120b1b-d348-4f76-fab3-5a4e50ce37c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 53\n",
            "Removed 53\n",
            "List is empty, nothing to remove\n",
            "Added 76\n",
            "Removed 76\n",
            "Added 59\n",
            "Removed 59\n",
            "Added 7\n",
            "Removed 7\n",
            "List is empty, nothing to remove\n",
            "Added 99\n",
            "Removed 99\n",
            "Added 55\n",
            "Removed 55\n",
            "List is empty, nothing to remove\n",
            "Added 2\n",
            "Removed 2\n",
            "Added 86\n",
            "Added 77\n",
            "Added 32\n",
            "Final list: [86, 77, 32]\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared resource: an empty list\n",
        "numbers = []\n",
        "\n",
        "# A lock to prevent race conditions\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        lock.acquire()  # Acquire the lock before modifying the list\n",
        "        try:\n",
        "            num = random.randint(1, 100)\n",
        "            numbers.append(num)\n",
        "            print(f\"Added {num}\")\n",
        "        finally:\n",
        "            lock.release()  # Release the lock after the modification\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some delay\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    for i in range(10):\n",
        "        lock.acquire()  # Acquire the lock before modifying the list\n",
        "        try:\n",
        "            if numbers:\n",
        "                num = numbers.pop(0)\n",
        "                print(f\"Removed {num}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove\")\n",
        "        finally:\n",
        "            lock.release()  # Release the lock after the modification\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some delay\n",
        "\n",
        "# Creating threads\n",
        "adder_thread = threading.Thread(target=add_numbers)\n",
        "remover_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Starting threads\n",
        "adder_thread.start()\n",
        "remover_thread.start()\n",
        "\n",
        "# Waiting for both threads to finish\n",
        "adder_thread.join()\n",
        "remover_thread.join()\n",
        "\n",
        "print(\"Final list:\", numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIQOH7JMDvv4"
      },
      "source": [
        "Q 5 ) Describe the methods and tools available in Python for safely sharing data between threads and\n",
        "processes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVZtbz0fEh_T"
      },
      "source": [
        "In Python, safely sharing data between threads and processes is critical to avoid issues such as race conditions, data corruption, and deadlocks. Python provides various methods and tools to ensure that data can be safely shared and accessed in both multithreading and multiprocessing environments. These tools help manage synchronization and communication between threads or processes, ensuring consistency and integrity of shared data.\n",
        "\n",
        "1. Methods and Tools for Safely Sharing Data Between Threads\n",
        "a) threading.Lock (Mutual Exclusion - Mutex)\n",
        "Purpose: A Lock ensures that only one thread can access a shared resource (e.g., a variable, data structure) at a time. It prevents multiple threads from executing a critical section of code simultaneously.\n",
        "Usage: Threads acquire the lock before accessing the shared resource and release it when done.\n",
        "•\tExample:\n",
        "python\n",
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "shared_data = 0\n",
        "\n",
        "def modify_data():\n",
        "    global shared_data\n",
        "    with lock:  # Acquire the lock before modifying the shared resource\n",
        "        shared_data += 1  # Critical section\n",
        "b) threading.RLock (Reentrant Lock)\n",
        "•\tPurpose: A Reentrant Lock (RLock) allows a thread to acquire the lock multiple times without causing a deadlock. This is useful if a thread needs to acquire the same lock in nested code blocks.\n",
        "•\tUsage: Similar to a Lock, but it allows the same thread to re-acquire the lock.\n",
        "•\tExample:\n",
        "python\n",
        "rlock = threading.RLock()\n",
        "\n",
        "def task():\n",
        "    with rlock:\n",
        "        with rlock:  # The same thread can acquire the lock multiple times\n",
        "            print(\"Acquired RLock twice\")\n",
        "c) threading.Condition\n",
        "•\tPurpose: A Condition is used for more complex synchronization, where threads need to wait for certain conditions to be met before proceeding. It allows one thread to signal other threads that a certain condition is true, usually after some shared data has been updated.\n",
        "•\tUsage: Threads wait for a condition, and another thread signals when the condition is met.\n",
        "•\tExample:\n",
        "python\n",
        "condition = threading.Condition()\n",
        "shared_data = []\n",
        "\n",
        "def consumer():\n",
        "    with condition:\n",
        "        condition.wait()  # Wait for the condition to be signaled\n",
        "        print(f\"Consumed: {shared_data.pop()}\")\n",
        "\n",
        "def producer():\n",
        "    with condition:\n",
        "        shared_data.append(1)\n",
        "        condition.notify()  # Signal the condition to the waiting thread\n",
        "d) threading.Semaphore\n",
        "•\tPurpose: A Semaphore is used to control access to a shared resource by multiple threads. It allows a certain number of threads to access the resource simultaneously.\n",
        "•\tUsage: Semaphores are useful when there is a limited number of resources, like database connections or file handles.\n",
        "•\tExample:\n",
        "python\n",
        "semaphore = threading.Semaphore(2)  # Only 2 threads can access the resource at a time\n",
        "\n",
        "def access_shared_resource():\n",
        "    with semaphore:\n",
        "        print(\"Accessing resource\")\n",
        "e) threading.Event\n",
        "•\tPurpose: An Event is used for communication between threads, allowing one thread to signal an event to other threads. Threads can either wait for an event to be set or proceed when the event is triggered.\n",
        "•\tUsage: Used for thread coordination and signaling.\n",
        "•\tExample:\n",
        "python\n",
        "event = threading.Event()\n",
        "\n",
        "def task():\n",
        "    event.wait()  # Wait for the event to be triggered\n",
        "    print(\"Event occurred\")\n",
        "\n",
        "def trigger_event():\n",
        "    event.set()  # Trigger the event\n",
        "2. Methods and Tools for Safely Sharing Data Between Processes\n",
        "Sharing data between processes is more complex than sharing data between threads because processes have separate memory spaces. Python’s multiprocessing module provides several tools for inter-process communication (IPC) and synchronization.\n",
        "a) multiprocessing.Queue\n",
        "•\tPurpose: A Queue is a thread-safe and process-safe FIFO (First In, First Out) data structure for communication between processes. Processes can safely put items into the queue and retrieve them.\n",
        "•\tUsage: Often used for producer-consumer patterns.\n",
        "•\tExample:\n",
        "python\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def producer(q):\n",
        "    q.put(\"data\")\n",
        "\n",
        "def consumer(q):\n",
        "    print(q.get())  # Safely get data from the queue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    q = Queue()\n",
        "    p1 = Process(target=producer, args=(q,))\n",
        "    p2 = Process(target=consumer, args=(q,))\n",
        "    p1.start()\n",
        "    p2.start()\n",
        "    p1.join()\n",
        "    p2.join()\n",
        "b) multiprocessing.Pipe\n",
        "•\tPurpose: A Pipe is a communication channel that allows data to be sent between two processes. It is a lower-level form of communication compared to a Queue.\n",
        "•\tUsage: Provides two connection objects (conn1, conn2) for sending and receiving messages between processes.\n",
        "•\tExample:\n",
        "python\n",
        "from multiprocessing import Process, Pipe\n",
        "\n",
        "def send_data(conn):\n",
        "    conn.send(\"Hello from sender!\")\n",
        "    conn.close()\n",
        "\n",
        "def receive_data(conn):\n",
        "    print(conn.recv())  # Safely receive data\n",
        "    conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parent_conn, child_conn = Pipe()\n",
        "    p1 = Process(target=send_data, args=(child_conn,))\n",
        "    p2 = Process(target=receive_data, args=(parent_conn,))\n",
        "    p1.start()\n",
        "    p2.start()\n",
        "    p1.join()\n",
        "    p2.join()\n",
        "c) multiprocessing.Manager\n",
        "•\tPurpose: A Manager provides a way to share Python objects like lists, dictionaries, and namespaces between processes. It allows processes to access shared data structures safely.\n",
        "•\tUsage: Useful when multiple processes need to access shared state.\n",
        "•\tExample:\n",
        "python\n",
        "from multiprocessing import Process, Manager\n",
        "\n",
        "def add_data(shared_list):\n",
        "    shared_list.append(\"data\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Manager() as manager:\n",
        "        shared_list = manager.list()  # Shared list\n",
        "        processes = [Process(target=add_data, args=(shared_list,)) for _ in range(5)]\n",
        "        \n",
        "        for p in processes:\n",
        "            p.start()\n",
        "        \n",
        "        for p in processes:\n",
        "            p.join()\n",
        "        \n",
        "        print(shared_list)  # All processes safely add to the shared list\n",
        "d) multiprocessing.Lock\n",
        "•\tPurpose: Just like threading.Lock, multiprocessing.Lock ensures that only one process at a time can access a shared resource. It is useful when processes need to update shared state and we want to avoid race conditions.\n",
        "•\tUsage: Critical sections of the code are protected by acquiring and releasing the lock.\n",
        "•\tExample:\n",
        "python\n",
        "from multiprocessing import Process, Lock\n",
        "\n",
        "def modify_shared_resource(lock):\n",
        "    with lock:\n",
        "        print(\"Modifying shared resource\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    lock = Lock()\n",
        "    processes = [Process(target=modify_shared_resource, args=(lock,)) for _ in range(3)]\n",
        "    \n",
        "    for p in processes:\n",
        "        p.start()\n",
        "    \n",
        "    for p in processes:\n",
        "        p.join()\n",
        "e) multiprocessing.Value and multiprocessing.Array\n",
        "•\tPurpose: These are shared, synchronized objects provided by the multiprocessing module. Value allows sharing a single value (e.g., an integer or float) between processes, while Array allows sharing a list-like array of values.\n",
        "•\tUsage: Useful for sharing primitive data types across processes.\n",
        "•\tExample:\n",
        "python\n",
        "Copy code\n",
        "from multiprocessing import Process, Value\n",
        "\n",
        "def increment_value(shared_value):\n",
        "    with shared_value.get_lock():  # Acquire the lock to prevent race conditions\n",
        "        shared_value.value += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    shared_value = Value('i', 0)  # 'i' for integer type\n",
        "    processes = [Process(target=increment_value, args=(shared_value,)) for _ in range(5)]\n",
        "    \n",
        "    for p in processes:\n",
        "        p.start()\n",
        "    \n",
        "    for p in processes:\n",
        "        p.join()\n",
        "    \n",
        "    print(\"Final value:\", shared_value.value)\n",
        "Summary\n",
        "•\tFor threads: Tools like Lock, RLock, Condition, Semaphore, and Event help ensure safe sharing and synchronization when accessing shared resources.\n",
        "•\tFor processes: multiprocessing.Queue, Pipe, Manager, Lock, Value, and Array provide mechanisms for inter-process communication and synchronization, ensuring safe access to shared data in multiprocessing contexts.\n",
        "These tools allow Python programs to safely manage concurrent access to shared data, preventing issues like race conditions and deadlocks in both multithreading and multiprocessing scenarios.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXCwt7kGOR71"
      },
      "source": [
        "Q 6) Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
        "doing so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-X8dVd0OWxx"
      },
      "source": [
        "Ans ) In concurrent programming, handling exceptions is crucial because multiple threads or processes are executing at the same time, which can increase the likelihood of errors. Without proper exception handling, issues such as race conditions, deadlocks, or inconsistent shared states can arise, leading to system crashes or unpredictable behavior. Here’s why handling exceptions in concurrent programs is important and the techniques to address them:\n",
        "\n",
        "Importance of Handling Exceptions in Concurrent Programs\n",
        "Preventing Crashes and Instability: If one thread encounters an unhandled exception, it may terminate prematurely, potentially leaving shared resources in an inconsistent state. This can cause other threads to fail, resulting in system crashes or unpredictable behavior.\n",
        "\n",
        "Ensuring Resource Cleanup: In concurrent systems, shared resources such as files, network connections, or memory need to be properly managed. Unhandled exceptions can leave these resources locked or unavailable, leading to deadlocks or resource leaks.\n",
        "\n",
        "Avoiding Deadlocks and Race Conditions: Exceptions that occur while a thread is holding a lock or performing critical operations can cause deadlocks or race conditions. Proper handling ensures that locks and resources are released, preventing these concurrency issues.\n",
        "\n",
        "Graceful Degradation: Proper exception handling allows concurrent programs to degrade gracefully. Instead of crashing, the program can recover from exceptions, retry failed operations, or safely shut down.\n",
        "\n",
        "Consistency of Shared State: Threads in concurrent programs often share data. Unhandled exceptions can lead to corrupted or inconsistent states, making the program’s output unreliable.\n",
        "\n",
        "Techniques for Handling Exceptions in Concurrent Programs\n",
        "Try-Catch Blocks (Thread-Level Handling): Wrapping concurrent code in try-catch blocks allows exceptions to be caught and handled within the thread, preventing unhandled exceptions from propagating and terminating the entire process.\n",
        "\n",
        "Example in Java:\n",
        "\n",
        "java\n",
        "Copy code\n",
        "Runnable task = () -> {\n",
        "    try {\n",
        "        // concurrent code\n",
        "    } catch (Exception e) {\n",
        "        // handle exception\n",
        "    }\n",
        "};\n",
        "new Thread(task).start();\n",
        "Thread Pool Exception Handling: When using thread pools (e.g., ExecutorService in Java), you can catch exceptions from individual tasks by handling them in the callable or runnable tasks submitted to the pool.\n",
        "\n",
        "In Java, using Callable allows you to throw checked exceptions:\n",
        "\n",
        "java\n",
        "Copy code\n",
        "ExecutorService executor = Executors.newFixedThreadPool(10);\n",
        "Future<?> future = executor.submit(() -> {\n",
        "    // concurrent code\n",
        "});\n",
        "try {\n",
        "    future.get();  // Throws exception if task failed\n",
        "} catch (ExecutionException | InterruptedException e) {\n",
        "    // handle exception\n",
        "}\n",
        "Using Promises/Futures: In many languages, promises or futures are used to represent the result of an asynchronous computation. They can catch exceptions that occur during the computation, which can then be handled when retrieving the result.\n",
        "\n",
        "Example in Python using concurrent.futures:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import traceback\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        # Concurrent code\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(task)\n",
        "    try:\n",
        "        result = future.result()  # Raises exception if task failed\n",
        "    except Exception as e:\n",
        "        # Handle exception\n",
        "        print(\"Exception caught:\", e)\n",
        "Handling Exceptions in Message-Passing Systems: In actor-based or message-passing models (e.g., Akka, Erlang), exceptions are often handled by sending error messages between actors. The receiving actor can then decide how to recover or restart.\n",
        "\n",
        "Example in Akka (Scala):\n",
        "\n",
        "scala\n",
        "Copy code\n",
        "class MyActor extends Actor {\n",
        "    def receive = {\n",
        "        case message =>\n",
        "            try {\n",
        "                // concurrent code\n",
        "            } catch {\n",
        "                case e: Exception =>\n",
        "                    // handle exception\n",
        "            }\n",
        "    }\n",
        "}\n",
        "Supervisory Strategies: In actor-based models, a supervisor strategy can be used to handle exceptions by restarting failed actors, resuming them, or stopping them based on the type of exception.\n",
        "\n",
        "Using Timeouts and Circuit Breakers: In concurrent programs where tasks are prone to failure or delays, timeouts can be used to prevent blocking forever. Circuit breakers can also be used to handle repeated failures by \"breaking\" the operation after a number of failures and attempting to restore the system after some time.\n",
        "\n",
        "Example in Python:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "from concurrent.futures import TimeoutError\n",
        "try:\n",
        "    future.result(timeout=5)  # Set timeout for the operation\n",
        "except TimeoutError:\n",
        "    # Handle timeout\n",
        "Custom Thread Wrappers: Wrapping threads in custom classes that handle exceptions can centralize exception handling. For example, in Java, you could extend Thread or Runnable to include exception handling logic, ensuring that all threads handle exceptions consistently.\n",
        "\n",
        "Logging and Monitoring: Centralized logging and monitoring of exceptions in concurrent systems are essential for diagnosing and recovering from failures. Proper logging ensures that failures are detected early, even if they don’t crash the entire system.\n",
        "\n",
        "Conclusion\n",
        "Exception handling in concurrent programming is crucial to maintaining system stability, ensuring proper resource management, and avoiding complex concurrency issues like deadlocks and race conditions. Techniques like try-catch blocks, thread pool handling, promises/futures, supervisory strategies, and message-passing models provide robust mechanisms for managing exceptions in concurrent environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlIpoX8aOdrT"
      },
      "source": [
        "Q 7 )  Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "Use concurrent.futures.ThreadPoolExecutor to manage the threads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iokSJ6-QOp2k"
      },
      "source": [
        "ANS ) Here’s an example program using concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tGP1PvdOr1M",
        "outputId": "b86b3f73-c1d8-4075-9ff5-307ca10c9dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating factorial of 1Calculating factorial of 2\n",
            "Calculating factorial of 3\n",
            "\n",
            "Calculating factorial of 4\n",
            "Calculating factorial of 5\n",
            "Calculating factorial of 6\n",
            "Result: 1\n",
            "Result: 120\n",
            "Result: 24\n",
            "Result: 720\n",
            "Result: 2\n",
            "Result: 6\n",
            "Calculating factorial of 7\n",
            "Calculating factorial of 8\n",
            "Calculating factorial of 9\n",
            "Calculating factorial of 10\n",
            "Result: 5040\n",
            "Result: 40320\n",
            "Result: 362880\n",
            "Result: 3628800\n"
          ]
        }
      ],
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Create a ThreadPoolExecutor\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # List of numbers from 1 to 10\n",
        "        numbers = range(1, 11)\n",
        "\n",
        "        # Submit tasks to the thread pool and store future objects\n",
        "        futures = [executor.submit(factorial, n) for n in numbers]\n",
        "\n",
        "        # As tasks complete, print their results\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            print(f\"Result: {future.result()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D54j6t2AO7kK"
      },
      "source": [
        "Q 8)  Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpy66enbO_JQ",
        "outputId": "a7589808-4f98-44bb-b8e9-45aff92aec88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using a pool of size 2\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.007274 seconds\n",
            "\n",
            "Using a pool of size 4\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.001791 seconds\n",
            "\n",
            "Using a pool of size 8\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.013066 seconds\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure the time taken to compute squares using a pool of different sizes\n",
        "def measure_pool_time(pool_size, numbers):\n",
        "    print(f\"\\nUsing a pool of size {pool_size}\")\n",
        "\n",
        "    # Create a Pool with the specified number of processes\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Compute the squares in parallel\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        print(f\"Results: {results}\")\n",
        "        print(f\"Time taken: {duration:.6f} seconds\")\n",
        "\n",
        "    return duration\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # List of numbers from 1 to 10\n",
        "    numbers = list(range(1, 11))\n",
        "\n",
        "    # Test pool sizes of 2, 4, and 8 processes\n",
        "    pool_sizes = [2, 4, 8]\n",
        "\n",
        "    for size in pool_sizes:\n",
        "        measure_pool_time(size, numbers)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
